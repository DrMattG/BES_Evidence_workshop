{
  "hash": "55dd9a17128c940304ca72c98c6dce84",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Meta-analysis in R\"\nformat: html\neditor: visual\nauthor: \"Matt & Phil\"\n---\n\n\n\n## Introduction\n\nThis exercise introduces meta-analysis concepts and methods, focusing on how they apply to ecological data. You will work with R to calculate effect sizes, understand fixed and random effects models, explore multi-level meta-analysis, and visualise results.\n\n### 1. Effect Sizes\n\n#### Objective: Learn about effect sizes and how to compute them for ecological studies\n\n[Effect sizes](https://matthewbjane.quarto.pub/Guide-to-Effect-Sizes-and-Confidence-Intervals.pdf \"Detailed overview of different effect sizes\") are key to synthesising study results in meta-analysis, as they provide a standardised way of comparing findings across studies. Common effect sizes include the standardised mean difference (Hedges' g in ecology), correlation coefficient, and log-transformed response ratio (lnRR).\n\nExample Code:\n\nWe have data from six fictional studies that examined species abundance before and after restoration efforts. The dataset includes: - Sample sizes before and after restoration (`n1` and `n2`). - Mean species abundance before and after (`m1` and `m2`). - Standard deviations of abundance before and after (`sd1` and `sd2`).\n\n| Study | Sample Size (Before) | Sample Size (After) | Mean Abundance (Before) | Mean Abundance (After) | SD (Before) | SD (After) |\n|----|----|----|----|----|----|----|\n| Smith_2015 | 30 | 28 | 5.2 | 3.9 | 1.1 | 0.9 |\n| Johnson_2017 | 50 | 48 | 6.1 | 5.4 | 1.3 | 1.1 |\n| Lee_2018 | 45 | 44 | 5.9 | 5.3 | 1.0 | 0.8 |\n| Gomez_2016 | 32 | 30 | 4.8 | 4.2 | 1.2 | 1.0 |\n| Patel_2019 | 40 | 39 | 5.5 | 4.9 | 1.4 | 1.2 |\n| Chen_2020 | 35 | 33 | 5.1 | 4.5 | 1.2 | 1.1 |\n\nThe **standardised mean difference (SMD)** between restored and control sites is calculated as follows:\n\n$$\\text{SMD} = \\frac{\\text{mean}_{\\text{restored}} - \\text{mean}_{\\text{control}}}{\\text{pooled standard deviation}}$$ Where the **pooled standard deviation** is calculated as:\n\n$$2SD_{\\text{pooled}} = \\sqrt{\\frac{(n_{\\text{restored}} - 1) \\cdot SD_{\\text{restored}}^2 + (n_{\\text{control}} - 1) \\cdot SD_{\\text{control}}^2}{n_{\\text{restored}} + n_{\\text{control}} - 2}}$$\n\nIn ecology we often have small sample sizes, so we use Hedges g to \"correct\" for small samples. The R package `metafor` calculates this for us using the `escalc` function.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Install metafor if you need to\n# install.packages(\"metafor\")\n# Load metafor\nlibrary(metafor)\n\n# Example dataset of ecological studies with mean outcomes and standard deviations\ndata <- data.frame(\nstudy = c(\"Smith_2015\", \"Johnson_2017\", \"Lee_2018\", \"Gomez_2016\", \"Patel_2019\", \"Chen_2020\"),\nn1 = c(30, 50, 45, 32, 40, 35),\nn2 = c(28, 48, 44, 30, 39, 33),\nm1 = c(5.2, 6.1, 5.9, 4.8, 5.5, 5.1),\nm2 = c(3.9, 5.4, 5.3, 4.2, 4.9, 4.5),\nsd1 = c(1.1, 1.3, 1.0, 1.2, 1.4, 1.2),\nsd2 = c(0.9, 1.1, 0.8, 1.0, 1.2, 1.1)\n)\n\n# Calculate standardised mean differences\ndata$yi <- escalc(measure=\"SMD\", m1i=m1, sd1i=sd1, n1i=n1, m2i=m2, sd2i=sd2, n2i=n2, data=data)$yi\ndata$vi <- escalc(measure=\"SMD\", m1i=m1, sd1i=sd1, n1i=n1, m2i=m2, sd2i=sd2, n2i=n2, data=data)$vi\n\ndata\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         study n1 n2  m1  m2 sd1 sd2        yi         vi\n1   Smith_2015 30 28 5.2 3.9 1.1 0.9 1.2716446 0.08298796\n2 Johnson_2017 50 48 6.1 5.4 1.3 1.1 0.5757711 0.04252472\n3     Lee_2018 45 44 5.9 5.3 1.0 0.8 0.6560309 0.04736734\n4   Gomez_2016 32 30 4.8 4.2 1.2 1.0 0.5347862 0.06688976\n5   Patel_2019 40 39 5.5 4.9 1.4 1.2 0.4552278 0.05195262\n6    Chen_2020 35 33 5.1 4.5 1.2 1.1 0.5146208 0.06082177\n```\n\n\n:::\n:::\n\n\n\n### 2. Fixed & Random Effects Meta-Analysis\n\n#### Objective: Understand and compare fixed-effect and random-effects models\n\nIn a fixed-effect model, we assume that all studies estimate the same true effect. In contrast, a random-effects model assumes that each study estimates its own effect size, accounting for between-study variability.\n\nFit both models and compare results.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fixed-effect model\nfixed_model <- rma(yi, vi, data = data, method=\"FE\")\nsummary(fixed_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFixed-Effects Model (k = 6)\n\n  logLik  deviance       AIC       BIC      AICc   \n  0.0727    5.9859    1.8547    1.6464    2.8547   \n\nI^2 (total heterogeneity / total variability):   16.47%\nH^2 (total variability / sampling variability):  1.20\n\nTest for Heterogeneity:\nQ(df = 5) = 5.9859, p-val = 0.3076\n\nModel Results:\n\nestimate      se    zval    pval   ci.lb   ci.ub      \n  0.6330  0.0965  6.5575  <.0001  0.4438  0.8222  *** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\n# Random-effects model\nrandom_model <- rma(yi, vi, data = data, method=\"REML\")\nsummary(random_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nRandom-Effects Model (k = 6; tau^2 estimator: REML)\n\n  logLik  deviance       AIC       BIC      AICc   \n -0.4504    0.9008    4.9008    4.1197   10.9008   \n\ntau^2 (estimated amount of total heterogeneity): 0.0000 (SE = 0.0350)\ntau (square root of estimated tau^2 value):      0.0010\nI^2 (total heterogeneity / total variability):   0.00%\nH^2 (total variability / sampling variability):  1.00\n\nTest for Heterogeneity:\nQ(df = 5) = 5.9859, p-val = 0.3076\n\nModel Results:\n\nestimate      se    zval    pval   ci.lb   ci.ub      \n  0.6330  0.0965  6.5574  <.0001  0.4438  0.8222  *** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n::: {.callout-note icon=\"false\"}\n## Discussion\n\nWhy might a random-effects model be more suitable for ecological data? What does the presence of between-study variance tell us?\n:::\n\n### 3.Multi-Level Meta-Analysis\n\n#### Objective: Explore multi-level meta-analysis to handle nested data structures (e.g., multiple effect sizes per study).\n\nMulti-level meta-analysis allows us to account for non-independence in data, such as when studies report multiple effect sizes, or when species are related to each other.\n\nHere we generate a simulated dataset with nested effect sizes and use `metafor` to fit a multi-level model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulated nested dataset\nmulti_data <- data.frame(\n  study = rep(c(\"Smith_2015\", \"Johnson_2017\", \"Lee_2018\", \"Gomez_2016\", \"Patel_2019\", \"Chen_2020\"), each = 2),\n  effect = rnorm(12, 0.5, 0.2),\n  vi = runif(12, 0.1, 0.2)\n)\n\n# Multi-level meta-analysis\nmulti_model <- rma.mv(effect, vi, random = ~ 1 | study, data = multi_data)\nsummary(multi_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMultivariate Meta-Analysis Model (k = 12; method: REML)\n\n  logLik  Deviance       AIC       BIC      AICc   \n -0.2291    0.4583    4.4583    5.2541    5.9583   \n\nVariance Components:\n\n            estim    sqrt  nlvls  fixed  factor \nsigma^2    0.0000  0.0000      6     no   study \n\nTest for Heterogeneity:\nQ(df = 11) = 1.8122, p-val = 0.9991\n\nModel Results:\n\nestimate      se    zval    pval   ci.lb   ci.ub      \n  0.5575  0.1071  5.2029  <.0001  0.3475  0.7675  *** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n::: {.callout-note icon=\"false\"}\n## Discussion:\n\nWhy might multi-level meta-analysis be relevant for ecology? How does this approach help with dependencies in data?\n:::\n\n### 4.Visualising Meta-Analysis Results\n\n#### Objective: Learn to create orchard plots to visualise meta-analysis results\n\nOrchard plots provide a clear visualisation of effect sizes and heterogeneity, making it easier to interpret meta-analysis outcomes.\n\nUse `orchard_plot()` to visualise the results from the random-effects model and multi-level model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install the package from GitHub\n# We need the remotes package first to do this\n# install.packages(\"remotes\")\n# remotes::install_github(\"daniel1noble/orchaRd\")\n# Load library orchaRd\nlibrary(orchaRd)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nLoading the 'orchaRd' package (version 2.0). For an\nintroduction and vignette to the package please see: https://daniel1noble.github.io/orchaRd/\n```\n\n\n:::\n\n```{.r .cell-code}\n# Orchard plot for the random-effects model\norchard_plot(random_model, xlab = \"Effect Size (Standardised Mean Difference)\",group=\"study\")\n```\n\n::: {.cell-output-display}\n![](meta_analysis_exercise_BES_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Orchard plot for the multi-level model\norchard_plot(multi_model, xlab = \"Effect Size (Standardised Mean Difference)\",group=\"study\")\n```\n\n::: {.cell-output-display}\n![](meta_analysis_exercise_BES_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n:::\n\n\n\n::: {.callout-note icon=\"false\"}\n## Discussion:\n\nHow does the plot help in interpreting effect sizes? What additional insights do you get from visualisations compared to numerical summaries?\n\nWhen might you choose a fixed-effect model over a random-effects model in ecology?\n\nHow can multi-level meta-analysis account for the complexities of ecological data?\n\nWhat are the benefits and limitations of visualizations in meta-analysis?\n:::\n\n### 5. Cumulative meta-analysis\n\n#### Objective: Learn to run a cumulative meta-analysis in R\n\nA **cumulative meta-analysis** examines how the overall effect size estimate changes as each study is added sequentially, usually sorted by publication date. This approach can reveal trends over time, showing whether the effect size has stabilised as more studies are included.\n\nLet's go through an example of performing a cumulative meta-analysis with the `metafor` package in R.\n\n##### Step 1: Create the Dataset\n\nFirst, we will create a dataset with a `year` variable to sort studies in chronological order for the cumulative analysis.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data.frame(\n  study_id = 1:10,\n  year = c(2000, 2002, 2004, 2005, 2006, 2008, 2010, 2012, 2015, 2018),  # Publication year\n  yi = c(0.8, 0.7, 0.5, 0.3, 0.1, -0.1, -0.3, -0.5, -0.7, -0.9),  # Effect sizes (Hedges' g)\n  vi = c(0.02, 0.03, 0.025, 0.04, 0.018, 0.027, 0.035, 0.033, 0.02, 0.03)  # Variances\n)\n\n# Sort data by year for cumulative meta-analysis\ndata <- data[order(data$year), ]\n```\n:::\n\n\n\n##### Step 2: Perform Cumulative Meta-Analysis\n\nNow, we can use the `cumul()` function from `metafor` to perform a cumulative meta-analysis. This function recalculates the meta-analysis result each time a new study is added.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit an initial random-effects model \nrandom_effect_model <- rma(yi = yi, vi = vi, data = data, method = \"REML\")  # Perform cumulative meta-analysis \ncumulative_results <- cumul(random_effect_model, order = data$year)  # View cumulative meta-analysis \ncumulative_results\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n   estimate     se    zval  pvals   ci.lb  ci.ub        Q     Qp   tau2      I2 \n1    0.8000 0.1414  5.6569 0.0000  0.5228 1.0772   0.0000 1.0000 0.0000  0.0000 \n2    0.7600 0.1095  6.9378 0.0000  0.5453 0.9747   0.2000 0.6547 0.0000  0.0000 \n3    0.6748 0.0938  7.1978 0.0000  0.4911 0.8586   2.0270 0.3629 0.0020  7.4829 \n4    0.5986 0.1060  5.6447 0.0000  0.3907 0.8064   4.9607 0.1747 0.0174 38.6738 \n5    0.4802 0.1343  3.5758 0.0003  0.2170 0.7434  15.5708 0.0037 0.0642 71.9936 \n6    0.3842 0.1449  2.6517 0.0080  0.1002 0.6681  25.8529 0.0001 0.0997 79.8004 \n7    0.2904 0.1548  1.8756 0.0607 -0.0131 0.5939  37.8277 0.0000 0.1403 84.2217 \n8    0.1927 0.1661  1.1607 0.2458 -0.1327 0.5182  55.7933 0.0000 0.1923 87.7058 \n9    0.0898 0.1780  0.5047 0.6138 -0.2590 0.4387  92.8590 0.0000 0.2578 90.8532 \n10  -0.0087 0.1871 -0.0462 0.9631 -0.3754 0.3581 123.1155 0.0000 0.3224 92.4608 \n        H2 \n1   1.0000 \n2   1.0000 \n3   1.0809 \n4   1.6306 \n5   3.5706 \n6   4.9506 \n7   6.3378 \n8   8.1339 \n9  10.9328 \n10 13.2640 \n```\n\n\n:::\n:::\n\n\n\n##### Step 3: Plot the Cumulative Meta-Analysis\n\nYou can visualize the cumulative effect size estimates over time using `forest()`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot cumulative meta-analysis results \nforest(cumulative_results, xlab = \"Cumulative Hedges' g\", refline = 0, cex = 0.8)\n```\n\n::: {.cell-output-display}\n![](meta_analysis_exercise_BES_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n##### Interpretation\n\nAs you add each study (from the earliest to the most recent), you will see how the cumulative estimate of Hedges' g changes. In ecology, this can highlight if early results were consistent with later studies or if new findings led to significant shifts in the overall effect estimate. This approach provides insight into whether further studies are likely to meaningfully alter the cumulative effect size or if it has stabilised.\n\n::: {.callout-note icon=\"false\"}\n## Discussion:\n\nHave a look at [this paper](https://onlinelibrary.wiley.com/doi/full/10.1002/jrsm.1691). What do the results of this study mean for evidence-informed decision making in ecology? What solutions can you think of to mitigate for this issue?\n:::\n",
    "supporting": [
      "meta_analysis_exercise_BES_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}